{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/melandur/tmp/csv/train/7_merged/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15040/168753961.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf_store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15040/168753961.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdf_store\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# TODO: check in file in file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/melandur/tmp/csv/train/7_merged/'"
     ]
    }
   ],
   "source": [
    "\"\"\"Load data as data frame\"\"\"\n",
    "src_train = '/home/melandur/tmp/csv/train/7_merged/'\n",
    "src_test = '/home/melandur/tmp/csv/test/7_merged/'\n",
    "\n",
    "def load_data(path):\n",
    "    files = os.listdir(path)\n",
    "    df_store = {}\n",
    "    for file in files: # TODO: check in file in file\n",
    "        if 'aha' in file in file and 'sample' not in file:\n",
    "            file_path = os.path.join(path, file)\n",
    "            df = pd.read_excel(file_path)\n",
    "            name = f\"{'_'.join(file.split('_')[1:3])}_{file.split('_')[-1]}\".split('.xlsx')[0]\n",
    "            if not 'global' in file:\n",
    "                df_store[name] = df.iloc[1:, 1:]  # drop first column and row\n",
    "    return df_store\n",
    "\n",
    "df_train = load_data(src_train)\n",
    "df_test = load_data(src_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclider(store, name, min=22, max=23):\n",
    "    euclid_store = {}\n",
    "    col_names = None\n",
    "    for idx in range(1, 17):\n",
    "        df_longit = store[f'longit_{name}_{idx}'].iloc[:, min:max]\n",
    "        df_circumf = store[f'circumf_{name}_{idx}'].iloc[:, min:max]\n",
    "        df_radial = store[f'radial_{name}_{idx}'].iloc[:, min:max]\n",
    "        col_names = df_longit.columns.values[0]  # get case name\n",
    "        # euclid distance\n",
    "        df_longit = abs(df_longit) ** 2\n",
    "        df_circumf = abs(df_circumf) ** 2\n",
    "        df_radial = abs(df_radial) ** 2\n",
    "        summed = df_longit + df_circumf.values + df_radial.values\n",
    "        clean = summed ** (1 / 2)\n",
    "        euclid_store[f'{idx}'] = clean\n",
    "    return euclid_store, col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(i):\n",
    "    x = df_e_train_s[f'{i}']\n",
    "    x = x.drop(x.tail(1).index).melt()\n",
    "    train_s = x.drop(x.columns[x.columns.str.contains('variable', case=False)], axis=1)['value']\n",
    "    y = df_e_test_s[f'{i}']\n",
    "    y = y.drop(y.tail(1).index).melt()\n",
    "    test_s = y.drop(y.columns[y.columns.str.contains('variable', case=False)], axis=1)['value']\n",
    "\n",
    "    x = df_e_train_v[f'{i}']\n",
    "    x = x.drop(x.tail(1).index).melt()\n",
    "    train_v = x.drop(x.columns[x.columns.str.contains('variable', case=False)], axis=1)['value']\n",
    "    y = df_e_test_v[f'{i}']\n",
    "    y = y.drop(y.tail(1).index).melt()\n",
    "    test_v = y.drop(y.columns[y.columns.str.contains('variable', case=False)], axis=1)['value']\n",
    "\n",
    "    x = df_e_train_a[f'{i}']\n",
    "    x = x.drop(x.tail(1).index).melt()\n",
    "    train_a = x.drop(x.columns[x.columns.str.contains('variable', case=False)], axis=1)['value']\n",
    "    y = df_e_test_a[f'{i}']\n",
    "    y = y.drop(y.tail(1).index).melt()\n",
    "    test_a = y.drop(y.columns[y.columns.str.contains('variable', case=False)], axis=1)['value']\n",
    "\n",
    "    x = df_e_train_sa[f'{i}']\n",
    "    x = x.drop(x.tail(1).index).melt()\n",
    "    train_sa = x.drop(x.columns[x.columns.str.contains('variable', case=False)], axis=1)['value']\n",
    "    y = df_e_test_sa[f'{i}']\n",
    "    y = y.drop(y.tail(1).index).melt()\n",
    "    test_sa = y.drop(y.columns[y.columns.str.contains('variable', case=False)], axis=1)['value']\n",
    "\n",
    "    train = pd.concat((train_v, train_s, train_a, train_sa), axis=1)\n",
    "    train.columns = ['velocity', 'strain_rate', 'acceleration', 'strain_acceleration']\n",
    "    test = pd.concat((test_v, test_s, test_a, test_sa), axis=1)\n",
    "    test.columns = ['velocity', 'strain_rate', 'acceleration', 'strain_acceleration']\n",
    "    return train, test\n",
    "\n",
    "def get_limits(use_test=False):\n",
    "    x_max, y_max, x_min, y_min = [], [], [], []\n",
    "    for i in range(1, 17):\n",
    "        data, test = get_data(i)\n",
    "        if use_test:\n",
    "            data = test\n",
    "        x_max.append(data.strain_acceleration.max())\n",
    "        x_min.append(data.strain_acceleration.min())\n",
    "        y_max.append(data.acceleration.max())\n",
    "        y_min.append(data.acceleration.min())\n",
    "    return max(x_max), min(x_min), max(y_max), min(y_min)\n",
    "\n",
    "\n",
    "for case_number in range(1, 50):\n",
    "    df_e_train_s, col_name = euclider(df_train, 'strain', min=case_number, max=case_number + 1)\n",
    "    df_e_test_s, _ = euclider(df_test, 'strain', min=case_number, max=case_number + 1)\n",
    "\n",
    "    df_e_train_v, _ = euclider(df_train, 'velocity', min=case_number, max=case_number + 1)\n",
    "    df_e_test_v, _ = euclider(df_test, 'velocity', min=case_number, max=case_number + 1)\n",
    "\n",
    "    df_e_train_a, _ = euclider(df_train, 'acceleration', min=case_number, max=case_number + 1)\n",
    "    df_e_test_a, _ = euclider(df_test, 'acceleration', min=case_number, max=case_number + 1)\n",
    "\n",
    "    df_e_train_sa, _ = euclider(df_train, 'strain-acc', min=case_number, max=case_number + 1)\n",
    "    df_e_test_sa, _ = euclider(df_test, 'strain-acc', min=case_number, max=case_number + 1)\n",
    "\n",
    "    for i in range(1, 17):\n",
    "        train, test = get_data(i)\n",
    "        x_max, x_min, y_max, y_min = get_limits(use_test=True)\n",
    "        # p = sns.jointplot(x=train.strain_acceleration, y=train.acceleration, xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        # plt.title(f'Train AHA {i}')\n",
    "        p = sns.jointplot(x=test.strain_acceleration, y=test.acceleration, xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        plt.title(f'Control\\n{col_name}\\nAHA {i}')\n",
    "        p.ax_joint.set_xlabel('strain-acceleration [1/s^2]')\n",
    "        p.ax_joint.set_ylabel('acceleration [mm/s^2]')\n",
    "        p.figure.tight_layout()\n",
    "        plt.show()\n",
    "        # plt.savefig(f'/home/melandur/Downloads/Pictures/images/test/case_{case_number}_AHA_{i}')\n",
    "        # plt.close()\n",
    "\n",
    "    # sns.jointplot(test.acceleration, test.velocity, xlim=(0,2), ylim=(0,50))\n",
    "    # plt.title(f'Cont_Segment {i}')\n",
    "    # plt.xlim(0,3)\n",
    "    # plt.ylim(0,50)\n",
    "\n",
    "    # sns.scatterplot(train.acceleration, train.velocity)\n",
    "    # sns.scatterplot(test.acceleration, test.strain_rate)\n",
    "    # plt.title('myocarditis')\n",
    "\n",
    "    # plt.subplot(122)\n",
    "    # plt.title('control')\n",
    "    # sns.scatterplot(test.strain_rate, test.velocity)\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(i):\n",
    "    x = df_e_train_s[f'{i}']\n",
    "    x = x.drop(x.tail(1).index).melt()\n",
    "    train_s = x.drop(x.columns[x.columns.str.contains('variable', case=False)], axis=1)['value']\n",
    "    y = df_e_test_s[f'{i}']\n",
    "    y = y.drop(y.tail(1).index).melt()\n",
    "    test_s = y.drop(y.columns[y.columns.str.contains('variable', case=False)], axis=1)['value']\n",
    "\n",
    "    x = df_e_train_v[f'{i}']\n",
    "    x = x.drop(x.tail(1).index).melt()\n",
    "    train_v = x.drop(x.columns[x.columns.str.contains('variable', case=False)], axis=1)['value']\n",
    "    y = df_e_test_v[f'{i}']\n",
    "    y = y.drop(y.tail(1).index).melt()\n",
    "    test_v = y.drop(y.columns[y.columns.str.contains('variable', case=False)], axis=1)['value']\n",
    "\n",
    "    x = df_e_train_a[f'{i}']\n",
    "    x = x.drop(x.tail(1).index).melt()\n",
    "    train_a = x.drop(x.columns[x.columns.str.contains('variable', case=False)], axis=1)['value']\n",
    "    y = df_e_test_a[f'{i}']\n",
    "    y = y.drop(y.tail(1).index).melt()\n",
    "    test_a = y.drop(y.columns[y.columns.str.contains('variable', case=False)], axis=1)['value']\n",
    "\n",
    "    x = df_e_train_sa[f'{i}']\n",
    "    x = x.drop(x.tail(1).index).melt()\n",
    "    train_sa = x.drop(x.columns[x.columns.str.contains('variable', case=False)], axis=1)['value']\n",
    "    y = df_e_test_sa[f'{i}']\n",
    "    y = y.drop(y.tail(1).index).melt()\n",
    "    test_sa = y.drop(y.columns[y.columns.str.contains('variable', case=False)], axis=1)['value']\n",
    "\n",
    "    train = pd.concat((train_v, train_s, train_a, train_sa), axis=1)\n",
    "    train.columns = ['velocity', 'strain_rate', 'acceleration', 'strain_acceleration']\n",
    "    test = pd.concat((test_v, test_s, test_a, test_sa), axis=1)\n",
    "    test.columns = ['velocity', 'strain_rate', 'acceleration', 'strain_acceleration']\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def rename_columns(df, i):\n",
    "    column_names = df.columns\n",
    "    new_names = []\n",
    "    for name in column_names:\n",
    "        new_names.append(f'{name}_{i}')\n",
    "    df.columns = new_names\n",
    "    return df\n",
    "\n",
    "for case_number in range(1, 50):\n",
    "    df_e_train_s, col_name = euclider(df_train, 'strain', min=case_number, max=case_number + 1)\n",
    "    df_e_test_s, _ = euclider(df_test, 'strain', min=case_number, max=case_number + 1)\n",
    "\n",
    "    df_e_train_v, _ = euclider(df_train, 'velocity', min=case_number, max=case_number + 1)\n",
    "    df_e_test_v, _ = euclider(df_test, 'velocity', min=case_number, max=case_number + 1)\n",
    "\n",
    "    df_e_train_a, _ = euclider(df_train, 'acceleration', min=case_number, max=case_number + 1)\n",
    "    df_e_test_a, _ = euclider(df_test, 'acceleration', min=case_number, max=case_number + 1)\n",
    "\n",
    "    df_e_train_sa, _ = euclider(df_train, 'strain-acc', min=case_number, max=case_number + 1)\n",
    "    df_e_test_sa, _ = euclider(df_test, 'strain-acc', min=case_number, max=case_number + 1)\n",
    "\n",
    "    # for i in range(1, 17):\n",
    "    #     if i == 1:\n",
    "    #         _, test = get_data(i)\n",
    "    #         fused_segs = rename_columns(test, i)\n",
    "    #     else:\n",
    "    #         train, test = get_data(i)\n",
    "    #         data = rename_columns(test, i)\n",
    "    #         fused_segs = fused_segs.join(data)\n",
    "    #\n",
    "    x_max, x_min, y_max, y_min = get_limits(use_test=False)\n",
    "    p = sns.jointplot(x=train.strain_acceleration, y=train.acceleration, xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    plt.title(f'Myo\\n{col_name}\\nAHA {i}')\n",
    "\n",
    "    # g = sns.PairGrid(fused_segs, diag_sharey=False)\n",
    "    # g.map_upper(sns.scatterplot)\n",
    "    # g.map_lower(sns.kdeplot)\n",
    "    # g.map_diag(sns.kdeplot)\n",
    "    # plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b7f01d46106d46af90ff4e07259698e02c99c1861de2cd96bb2d98a11b966ed3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
